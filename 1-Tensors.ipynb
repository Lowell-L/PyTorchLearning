{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 直接从数据初始化，数据类型可以指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# torch.tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False)\n",
    "\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data, dtype=float)    # data 可以是 list，numpy\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 根据 Numpy 的数组生成 **torch.from_numpy(ndarray)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 5]], dtype=torch.int32)\n",
      "[[1 2]\n",
      " [3 5]]\n"
     ]
    }
   ],
   "source": [
    "# 利用这个方法创建的 tensor 和原来的 ndarray 共享内存，当修改其中一个数据，另外一个也会被改动。\n",
    "x_np[1, 1] = 5\n",
    "print(x_np)\n",
    "print(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 根据另一个 Tensor 的形状和数据类型来生成新的 Tensor，除非通过重写改变了新 Tensor 的形状或数据类型<br>   **torch.ones_like()、torch.rand_like()、torch.zeros_like()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1., 1.],\n",
      "        [1., 1.]], dtype=torch.float64) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0, 0],\n",
      "        [0, 0]], dtype=torch.int32) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.7367, 0.5138],\n",
      "        [0.9785, 0.7209]], dtype=torch.float64) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.1101, 0.1300],\n",
      "        [0.7923, 0.9408]], dtype=torch.float64) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)    # 保留原 Tensor 的形状和数据类型！\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_zero = torch.zeros_like(x_np)\n",
    "print(f\"Zeros Tensor: \\n {x_zero} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data)\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_np, dtype = float)   # x_np.dtype = int32，这里重写为 float\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. shape 是一个元组，shape 变量决定了 Tensor 的形状/维度，使用 **torch.ones()、torch.rand()、torch.zeros()** 并输入 shape 作为参数来生成 Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.3235, 0.4753, 0.5395],\n",
      "        [0.1866, 0.7378, 0.0505]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3, 4)\n",
    "\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.使用某一个值填充某个形状的张量，如 torch.full(size, full_value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[6, 6],\n",
      "         [6, 6]],\n",
      "\n",
      "        [[6, 6],\n",
      "         [6, 6]],\n",
      "\n",
      "        [[6, 6],\n",
      "         [6, 6]]])\n"
     ]
    }
   ],
   "source": [
    "# torch.full(size, fill_value, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "tensor = torch.full((3, 2, 2), 6)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 使用 torch.arange()、torch.linspace()、torch.logspace() 创建一维张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 5, 7, 9])\n"
     ]
    }
   ],
   "source": [
    "# 创建 [start, end) 的等差一维张量\n",
    "# torch.arange(start=0, end, step=1, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "tensor = torch.arange(3, 10, 2) # 创建 [3, 10) 内 公差为 2 的等差数列 一维张量\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1.,  12.,  23.,  34.,  45.,  56.,  67.,  78.,  89., 100.])\n"
     ]
    }
   ],
   "source": [
    "# 创建 [start, end] 的均分一维张量\n",
    "# torch.linspace(start, end, steps=100, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "tensor = torch.linspace(1, 100, 10) # 创建一个 [start, end] 的含有 stpes 个数字的一维均分张量\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 使用 torch.eye(n) 创建单位对角矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.eye(n, m=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "tensor = torch.eye(4)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 根据概率创建 Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Tensor 的属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3, 4)                               # 参数中有 *，表示 size 可以输入任意个参数\n",
    "print(f\"Shape of tensor: {tensor.shape}\")               # Tensor 的形状\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")            # Tensor 的数据类型\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")   # Tensor 的存储设备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 将张量在原有维度上拼接 torch.cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6568, 0.3033, 0.0065],\n",
      "        [0.7642, 0.4486, 0.3084]])\n",
      "tensor([[0.8015, 0.1249, 0.1277],\n",
      "        [0.7384, 0.4433, 0.6212]])\n"
     ]
    }
   ],
   "source": [
    "# torch.cat(tensors, dim=0, out=None)\n",
    "# tensors 表示要拼接的张量序列， dim 表示按照哪个维度进行拼接\\\n",
    "\n",
    "tensor_1 = torch.rand(2, 3)\n",
    "tensor_2 = torch.rand(2, 3)\n",
    "print(tensor_1)\n",
    "print(tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6568, 0.3033, 0.0065],\n",
      "        [0.7642, 0.4486, 0.3084],\n",
      "        [0.8015, 0.1249, 0.1277],\n",
      "        [0.7384, 0.4433, 0.6212]])\n"
     ]
    }
   ],
   "source": [
    "tensor_cat = torch.cat([tensor_1, tensor_2], 0)\n",
    "print(tensor_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8660],\n",
      "        [0.9512]])\n",
      "tensor([[0.2885, 0.2986, 0.3893, 0.8238, 0.6950],\n",
      "        [0.1197, 0.7716, 0.1898, 0.7740, 0.8018]])\n",
      "tensor([[0.2885, 0.2986, 0.3893, 0.8238, 0.6950, 0.8660],\n",
      "        [0.1197, 0.7716, 0.1898, 0.7740, 0.8018, 0.9512]])\n"
     ]
    }
   ],
   "source": [
    "tensor_A = torch.rand(2, 1)\n",
    "tensor_B = torch.rand(2, 5)\n",
    "tensor_cat = torch.cat([tensor_B, tensor_A], 1)\n",
    "print(tensor_A)     # tensor_A.size = [2, 1]\n",
    "print(tensor_B)     # tensor_B.size = [2, 5]\n",
    "print(tensor_cat)   # tensor_cat.size = [2, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于在某个维度上的拼接：以二维张量举例，想象两个二维张量 A，B 是两片辣条，其分别在第一维度 x 和第二维度 y 上各有一个竹签。\n",
    "<br>把 A 和 B 在第一维度上拼接，（如果 Tensors 序列是 [A, B]），也即把辣条 B 沿着辣条 A 的 第一维度 x 的竹签穿进去，A 在上 B 在下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8f61be024eba58adef938c9aa1e29e02cb3dece83a5348b1a2dafd16a070453"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
